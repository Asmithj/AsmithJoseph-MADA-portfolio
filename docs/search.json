[
  {
    "objectID": "ml-models-exercise/ml-models-exercise.html",
    "href": "ml-models-exercise/ml-models-exercise.html",
    "title": "Machine Learning Models 1",
    "section": "",
    "text": "# Load necessary packages\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(tidymodels)  # for modeling and data splitting\n\nWarning: package 'tidymodels' was built under R version 4.4.2\n\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.3.0 ──\n\n\n✔ broom        1.0.8     ✔ rsample      1.2.1\n✔ dials        1.4.0     ✔ tibble       3.2.1\n✔ ggplot2      3.5.1     ✔ tidyr        1.3.1\n✔ infer        1.0.7     ✔ tune         1.3.0\n✔ modeldata    1.4.0     ✔ workflows    1.2.0\n✔ parsnip      1.3.0     ✔ workflowsets 1.1.0\n✔ purrr        1.0.4     ✔ yardstick    1.3.2\n✔ recipes      1.1.1     \n\n\nWarning: package 'dials' was built under R version 4.4.2\n\n\nWarning: package 'scales' was built under R version 4.4.2\n\n\nWarning: package 'ggplot2' was built under R version 4.4.3\n\n\nWarning: package 'infer' was built under R version 4.4.2\n\n\nWarning: package 'modeldata' was built under R version 4.4.2\n\n\nWarning: package 'parsnip' was built under R version 4.4.2\n\n\nWarning: package 'purrr' was built under R version 4.4.2\n\n\nWarning: package 'recipes' was built under R version 4.4.2\n\n\nWarning: package 'rsample' was built under R version 4.4.3\n\n\nWarning: package 'tune' was built under R version 4.4.2\n\n\nWarning: package 'workflows' was built under R version 4.4.2\n\n\nWarning: package 'workflowsets' was built under R version 4.4.2\n\n\nWarning: package 'yardstick' was built under R version 4.4.2\n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ purrr::discard() masks scales::discard()\n✖ dplyr::filter()  masks stats::filter()\n✖ dplyr::lag()     masks stats::lag()\n✖ recipes::step()  masks stats::step()\n\nlibrary(ggplot2)     # for visualization\nlibrary(here)        # for managing file paths\n\nWarning: package 'here' was built under R version 4.4.2\n\n\nhere() starts at C:/Users/ajose35/Desktop/MADA-course/AsmithJoseph-MADA-portfolio\n\nlibrary(corrplot)\n\nWarning: package 'corrplot' was built under R version 4.4.2\n\n\ncorrplot 0.95 loaded\n\nlibrary(ranger)      # for random forest via ranger\n\nWarning: package 'ranger' was built under R version 4.4.3\n\nlibrary(glmnet)      # for LASSO via glmnet\n\nWarning: package 'glmnet' was built under R version 4.4.3\n\n\nLoading required package: Matrix\n\n\nWarning: package 'Matrix' was built under R version 4.4.3\n\n\n\nAttaching package: 'Matrix'\n\n\nThe following objects are masked from 'package:tidyr':\n\n    expand, pack, unpack\n\n\nLoaded glmnet 4.1-8\n\nlibrary(readr)       # for reading CSV files\n\nWarning: package 'readr' was built under R version 4.4.2\n\n\n\nAttaching package: 'readr'\n\n\nThe following object is masked from 'package:yardstick':\n\n    spec\n\n\nThe following object is masked from 'package:scales':\n\n    col_factor\n\n# Set up output folder using the here package\noutput_folder &lt;- here::here(\"ml-models-exercise\")\nif (!dir.exists(output_folder)) {\n  dir.create(output_folder, recursive = TRUE)\n}\nrds_file_path &lt;- file.path(output_folder, \"clean_data.rds\")\n\n# Preliminaries: Set a random seed for reproducibility\nset.seed(1234)\n\n# Load the clean data from the RDS file\nclean_data &lt;- readRDS(rds_file_path)\n\n# Verify the loaded data\nstr(clean_data)\n\ntibble [120 × 6] (S3: tbl_df/tbl/data.frame)\n $ Y   : num [1:120] 2691 2639 2150 1789 3126 ...\n $ DOSE: num [1:120] 25 25 25 25 25 25 25 25 25 25 ...\n $ AGE : num [1:120] 42 24 31 46 41 27 23 20 23 28 ...\n $ SEX : Factor w/ 2 levels \"1\",\"2\": 1 1 1 2 2 1 1 1 1 1 ...\n $ WT  : num [1:120] 94.3 80.4 71.8 77.4 64.3 ...\n $ HT  : num [1:120] 1.77 1.76 1.81 1.65 1.56 ...\n\nprint(colnames(clean_data))\n\n[1] \"Y\"    \"DOSE\" \"AGE\"  \"SEX\"  \"WT\"   \"HT\""
  },
  {
    "objectID": "ml-models-exercise/ml-models-exercise.html#model-fitting",
    "href": "ml-models-exercise/ml-models-exercise.html#model-fitting",
    "title": "Machine Learning Models 1",
    "section": "Model Fitting",
    "text": "Model Fitting\nBelow is the code I wrote to fit my three models—a linear regression using all predictors, a LASSO regression (with penalty = 0.1), and a random forest—using the entire dataset (no train/test split) and then making predictions and computing the RMSE for each model. I also generate an observed versus predicted plot for each model.\n\n# Set seed for reproducibility\nset.seed(1234)\n\n\n\n# Model 1: Linear Regression with all predictors\nlm_recipe &lt;- recipe(Y ~ DOSE + AGE + SEX + RACE + WT + HT, \n                    data = Mav.final_data_selected)\nlm_model &lt;- linear_reg() %&gt;%\n  set_engine(\"lm\") %&gt;%\n  set_mode(\"regression\")\nlm_workflow &lt;- workflow() %&gt;%\n  add_model(lm_model) %&gt;%\n  add_recipe(lm_recipe)\nlm_fit &lt;- lm_workflow %&gt;% fit(data = Mav.final_data_selected)\nlm_predictions &lt;- predict(lm_fit, new_data = Mav.final_data_selected) %&gt;%\n  bind_cols(Mav.final_data_selected)\nlm_rmse &lt;- rmse(lm_predictions, truth = Y, estimate = .pred)\nprint(\"Linear Model RMSE:\")\n\n[1] \"Linear Model RMSE:\"\n\nprint(lm_rmse)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       1183.\n\nggplot(lm_predictions, aes(x = Y, y = .pred)) +\n  geom_point() +\n  geom_abline(slope = 1, intercept = 0, linetype = \"dashed\") +\n  labs(title = \"Linear Model: Observed vs. Predicted\",\n       x = \"Observed Y\", y = \"Predicted Y\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nModel 2: LASSO Regression\n\n# Model 2: LASSO Regression (penalty = 0.1, mixture = 1 for LASSO)\nlasso_recipe &lt;- recipe(Y ~ DOSE + AGE + SEX + RACE + WT + HT, \n                       data = Mav.final_data_selected) %&gt;%\n  step_dummy(all_nominal_predictors())\n\nlasso_model &lt;- linear_reg(penalty = 0.1, mixture = 1) %&gt;% \n  set_engine(\"glmnet\") %&gt;% \n  set_mode(\"regression\")\n\nlasso_workflow &lt;- workflow() %&gt;%\n  add_model(lasso_model) %&gt;%\n  add_recipe(lasso_recipe)\n\nlasso_fit &lt;- lasso_workflow %&gt;% fit(data = Mav.final_data_selected)\n\nModel 3: Random Forest using ranger\n\n# Model 3: Random Forest using ranger (with seed = 1234)\nrf_recipe &lt;- recipe(Y ~ DOSE + AGE + SEX + RACE + WT + HT, \n                    data = Mav.final_data_selected)\nrf_model &lt;- rand_forest() %&gt;% \n  set_engine(\"ranger\", seed = 1234) %&gt;%\n  set_mode(\"regression\")\nrf_workflow &lt;- workflow() %&gt;%\n  add_model(rf_model) %&gt;%\n  add_recipe(rf_recipe)\nrf_fit &lt;- rf_workflow %&gt;% fit(data = Mav.final_data_selected)\nrf_predictions &lt;- predict(rf_fit, new_data = Mav.final_data_selected) %&gt;%\n  bind_cols(Mav.final_data_selected)\nrf_rmse &lt;- rmse(rf_predictions, truth = Y, estimate = .pred)\nprint(\"Random Forest Model RMSE:\")\n\n[1] \"Random Forest Model RMSE:\"\n\nprint(rf_rmse)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard        583.\n\nggplot(rf_predictions, aes(x = Y, y = .pred)) +\n  geom_point() +\n  geom_abline(slope = 1, intercept = 0, linetype = \"dashed\") +\n  labs(title = \"Random Forest: Observed vs. Predicted\",\n       x = \"Observed Y\", y = \"Predicted Y\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nI encountered an error because glmnet expects a numeric matrix, so I needed to convert my factor variables (SEX and RACE) into dummy variables. I fixed this by adding the step_dummy(all_nominal_predictors()) in my recipe. Then, when selecting the best penalty, I used the named argument metric = “rmse” in the select_best() function to avoid the error about the extra argument. This updated code now properly tunes the LASSO model.  I found that my linear model produced an RMSE of about 1183, while the random forest model achieved a much lower RMSE of around 582. When I examined the observed versus predicted plots, I noticed that the linear model’s predictions were more scattered around the diagonal—indicating larger residuals—whereas the random forest’s predictions clustered closely along the 45° line. This tells me that the random forest captures much more of the variability in Y and yields more accurate predictions than the linear model."
  }
]